{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment a - Linguistics\n",
    "\n",
    "## Boise State University NLP - Dr. Kennington\n",
    "\n",
    "### Instructions and Hints:\n",
    "\n",
    "* For this assignment, we will be looking at tokenization, morphology, and syntax. \n",
    "* This will follow in a similar way as the notebook we did in class, though it will be a bit more work. \n",
    "* Answer each question (or, in some cases, follow the command)\n",
    "* Follow the instructions on the corresponding assignment Trello card for submitting your assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will be using **[Tamarian](https://www.youtube.com/watch?v=ANvlLcOTy6M)** as our example language: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================================\n",
      "Assignment: A4 Linguistics\n",
      "OK, version v1.18.1\n",
      "=====================================================================\n",
      "\n",
      "\n",
      "Open the following URL:\n",
      "\n",
      "https://okpy.org/client/login/\n",
      "\n",
      "After logging in, copy the code from the web page and paste it into the box.\n",
      "Then press the \"Enter\" key on your keyboard.\n",
      "\n",
      "Paste your code here: JgWvdjQvDOPdZnZbmKQDw1VRZNnMQD\n",
      "Successfully logged in as SajiaZafreen@u.boisestate.edu\n"
     ]
    }
   ],
   "source": [
    "from client.api.notebook import Notebook\n",
    "\n",
    "ok = Notebook('a4.ok')\n",
    "\n",
    "ok.auth(inline=True, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    'Sinda his face black his eyes red',\n",
    "    'Tamak',\n",
    "    'The river Tamak in winter',\n",
    "    'Darmok and Jalad at Tanagra',\n",
    "    'Darmok and Jalad on the ocean',\n",
    "    'Socath his eyes opened',\n",
    "    'The beast of Tanagra Usani his army Jakka when the walls fell', # don't worry about this one\n",
    "    'Picard and Dathan at Eladrel',\n",
    "    'Marab with sails unfurled',\n",
    "    'Timba his arms open',\n",
    "    'Timba at rest'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Tokenize the sentences \n",
    "\n",
    "* you will need to make sure everything is lower case\n",
    "* you will need to represent the sentences as a 2D array of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sinda his face black his eyes red',\n",
       " 'tamak',\n",
       " 'the river tamak in winter',\n",
       " 'darmok and jalad at tanagra',\n",
       " 'darmok and jalad on the ocean',\n",
       " 'socath his eyes opened',\n",
       " 'the beast of tanagra usani his army jakka when the walls fell',\n",
       " 'picard and dathan at eladrel',\n",
       " 'marab with sails unfurled',\n",
       " 'timba his arms open',\n",
       " 'timba at rest']"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_lower = [each_string.lower() for each_string in sentences]\n",
    "sentence_lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_word = []\n",
    "for sen in sentence_lower:\n",
    "    words = sen.split()\n",
    "    list_word.append(words)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['sinda', 'his', 'face', 'black', 'his', 'eyes', 'red'],\n",
       " ['tamak'],\n",
       " ['the', 'river', 'tamak', 'in', 'winter'],\n",
       " ['darmok', 'and', 'jalad', 'at', 'tanagra'],\n",
       " ['darmok', 'and', 'jalad', 'on', 'the', 'ocean'],\n",
       " ['socath', 'his', 'eyes', 'opened'],\n",
       " ['the',\n",
       "  'beast',\n",
       "  'of',\n",
       "  'tanagra',\n",
       "  'usani',\n",
       "  'his',\n",
       "  'army',\n",
       "  'jakka',\n",
       "  'when',\n",
       "  'the',\n",
       "  'walls',\n",
       "  'fell'],\n",
       " ['picard', 'and', 'dathan', 'at', 'eladrel'],\n",
       " ['marab', 'with', 'sails', 'unfurled'],\n",
       " ['timba', 'his', 'arms', 'open'],\n",
       " ['timba', 'at', 'rest']]"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_2D = np.array(list_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list(['sinda', 'his', 'face', 'black', 'his', 'eyes', 'red']),\n",
       "       list(['tamak']), list(['the', 'river', 'tamak', 'in', 'winter']),\n",
       "       list(['darmok', 'and', 'jalad', 'at', 'tanagra']),\n",
       "       list(['darmok', 'and', 'jalad', 'on', 'the', 'ocean']),\n",
       "       list(['socath', 'his', 'eyes', 'opened']),\n",
       "       list(['the', 'beast', 'of', 'tanagra', 'usani', 'his', 'army', 'jakka', 'when', 'the', 'walls', 'fell']),\n",
       "       list(['picard', 'and', 'dathan', 'at', 'eladrel']),\n",
       "       list(['marab', 'with', 'sails', 'unfurled']),\n",
       "       list(['timba', 'his', 'arms', 'open']),\n",
       "       list(['timba', 'at', 'rest'])], dtype=object)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Use a stemmer or lemmatizer \n",
    "\n",
    "- (NLTK has several) \n",
    "-  You will know your stemmer/lemmatizer did its job because plural words will no longer be plural (e.g., 'eyes' -> 'eye') and past-tense words will no longer be past-tense (e.g. 'unfurled' -> 'unfurl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "lemma_sentences = []\n",
    "for i in range(0, len(list_word)):\n",
    "     l1 = list_word[i]\n",
    "     l2 = ' '.join([lemmatizer.lemmatize(word, 'v') for word in l1])\n",
    "     lemma_sentences.append(l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sinda his face black his eye red',\n",
       " 'tamak',\n",
       " 'the river tamak in winter',\n",
       " 'darmok and jalad at tanagra',\n",
       " 'darmok and jalad on the ocean',\n",
       " 'socath his eye open',\n",
       " 'the beast of tanagra usani his army jakka when the wall fell',\n",
       " 'picard and dathan at eladrel',\n",
       " 'marab with sail unfurl',\n",
       " 'timba his arm open',\n",
       " 'timba at rest']"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_list_words = []\n",
    "for sen in lemma_sentences:\n",
    "    words = sen.split()\n",
    "    lemma_list_words.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['sinda', 'his', 'face', 'black', 'his', 'eye', 'red'],\n",
       " ['tamak'],\n",
       " ['the', 'river', 'tamak', 'in', 'winter'],\n",
       " ['darmok', 'and', 'jalad', 'at', 'tanagra'],\n",
       " ['darmok', 'and', 'jalad', 'on', 'the', 'ocean'],\n",
       " ['socath', 'his', 'eye', 'open'],\n",
       " ['the',\n",
       "  'beast',\n",
       "  'of',\n",
       "  'tanagra',\n",
       "  'usani',\n",
       "  'his',\n",
       "  'army',\n",
       "  'jakka',\n",
       "  'when',\n",
       "  'the',\n",
       "  'wall',\n",
       "  'fell'],\n",
       " ['picard', 'and', 'dathan', 'at', 'eladrel'],\n",
       " ['marab', 'with', 'sail', 'unfurl'],\n",
       " ['timba', 'his', 'arm', 'open'],\n",
       " ['timba', 'at', 'rest']]"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma_list_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Write a grammar that can parse all of the sentences\n",
    "\n",
    "* Try to write as few grammar rules as possible\n",
    "* Use recursion where you can\n",
    "* Use `S` as the start symbol\n",
    "* All terminals need to be in quotes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "tamarian_grammar = nltk.CFG.fromstring(\"\"\"\n",
    " S -> NP RP | NP\n",
    " RP -> Ph | Ph RP\n",
    " Ph -> Pnn Nom | PP Nom | Nom | PrN | Adv Nom\n",
    " Nom -> N | N Adj | At N | N V | PP PrN | PP PrN Adj | At N V \n",
    " NP -> PrN | Nom | PrN Com NP \n",
    " Pnn -> \"his\" \n",
    " PrN -> \"sinda\" | \"tamak\" | \"darmok\" | \"jalad\" | \"tanagra\" | \"socath\" | \"picard\" | \"dathan\" | \"eladrel\" | \"marab\" | \"timba\"  \n",
    " At -> \"a\" | \"an\" | \"the\"\n",
    " V -> \"open\" | \"unfurl\" | \"fell\" \n",
    " Com -> \"and\" \n",
    " Adj -> \"red\" | \"black\" | \"jakka\" | \"usani\"  \n",
    " Adv -> \"when\" \n",
    " N -> \"eye\" | \"arm\" | \"sail\" | \"face\" | \"ocean\" | \"winter\" | \"river\" | \"rest\" | \"beast\" | \"army\" | \"wall\" \n",
    " PP -> \"in\" | \"at\" | \"on\" | \"with\" | \"of\" \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Show that your grammar parses all of the sentences\n",
    "\n",
    "* Use a parser that can use a CFG (NLTK has several) \n",
    "* Make sure there is a parse tree for each of the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP (PrN sinda))\n",
      "  (RP\n",
      "    (Ph (Pnn his) (Nom (N face) (Adj black)))\n",
      "    (RP (Ph (Pnn his) (Nom (N eye) (Adj red))))))\n",
      "(S (NP (PrN tamak)))\n",
      "(S\n",
      "  (NP (Nom (At the) (N river)))\n",
      "  (RP (Ph (PrN tamak)) (RP (Ph (PP in) (Nom (N winter))))))\n",
      "(S\n",
      "  (NP (PrN darmok) (Com and) (NP (PrN jalad)))\n",
      "  (RP (Ph (Nom (PP at) (PrN tanagra)))))\n",
      "(S\n",
      "  (NP (PrN darmok) (Com and) (NP (PrN jalad)))\n",
      "  (RP (Ph (PP on) (Nom (At the) (N ocean)))))\n",
      "(S (NP (PrN socath)) (RP (Ph (Pnn his) (Nom (N eye) (V open)))))\n",
      "(S\n",
      "  (NP (Nom (At the) (N beast)))\n",
      "  (RP\n",
      "    (Ph (Nom (PP of) (PrN tanagra) (Adj usani)))\n",
      "    (RP\n",
      "      (Ph (Pnn his) (Nom (N army) (Adj jakka)))\n",
      "      (RP (Ph (Adv when) (Nom (At the) (N wall) (V fell)))))))\n",
      "(S\n",
      "  (NP (PrN picard) (Com and) (NP (PrN dathan)))\n",
      "  (RP (Ph (Nom (PP at) (PrN eladrel)))))\n",
      "(S (NP (PrN marab)) (RP (Ph (PP with) (Nom (N sail) (V unfurl)))))\n",
      "(S (NP (PrN timba)) (RP (Ph (Pnn his) (Nom (N arm) (V open)))))\n",
      "(S (NP (PrN timba)) (RP (Ph (PP at) (Nom (N rest)))))\n"
     ]
    }
   ],
   "source": [
    "parser = nltk.ChartParser(tamarian_grammar)\n",
    "\n",
    "for sent in lemma_list_words:\n",
    "    for tree in parser.parse(sent):\n",
    "        print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For questions 5-7, just answer in marktown/raw text. No code necessary.\n",
    "\n",
    "## 5. Does your parser have full coverage?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It does have full coverage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Does your parser over-generate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It does not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Which sentences are ambiguous? How do you know?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no over-generated sentences, so there is no ambiguity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Parse this sentence:\n",
    "\n",
    "* If you wrote your grammar right, this should be covered. If this isn't covered, then you'll need to go back and change your grammar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = ['timba', 'his', 'face', 'red', 'his', 'eye', 'black', 'in', 'winter']\n",
    "s1 = ['timba', 'his', 'face', 'red']\n",
    "#The beast of Tanagra Usani his army Jakka when the walls fell\n",
    "#s2 = ['the', 'beast', 'of', 'tanagra', 'usani', 'his', 'army', 'jakka', 'when', 'the', 'wall', 'fell']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP (Nom (At the) (N beast)))\n",
      "  (RP\n",
      "    (Ph (Nom (PP of) (PrN tanagra) (Adj usani)))\n",
      "    (RP\n",
      "      (Ph (Pnn his) (Nom (N army) (Adj jakka)))\n",
      "      (RP (Ph (Adv when) (Nom (At the) (N wall) (V fell)))))))\n"
     ]
    }
   ],
   "source": [
    "parser = nltk.RecursiveDescentParser(tamarian_grammar)\n",
    "for tree in parser.parse(s2):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP (PrN timba))\n",
      "  (RP\n",
      "    (Ph (Pnn his) (Nom (N face) (Adj red)))\n",
      "    (RP\n",
      "      (Ph (Pnn his) (Nom (N eye) (Adj black)))\n",
      "      (RP (Ph (PP in) (Nom (N winter)))))))\n"
     ]
    }
   ],
   "source": [
    "parser = nltk.RecursiveDescentParser(tamarian_grammar)\n",
    "for tree in parser.parse(s):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Was your result in Questions 8 ambiguous?\n",
    "\n",
    "* Answer in markdown or raw text, no code necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "No"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 10. How expressive is your language?\n",
    "\n",
    "* Answer in markdown or raw text, no code necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wouldn't say Tamarian Language is expressive. There are missing auxilliary verbs, ambiguous use of modifiers like adjectives and adverbs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Make the grammar more general by treating POS tags as the terminals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "tamarian_grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S -> NP RP | NP\n",
    "    RP -> Ph | Ph RP\n",
    "    Ph -> \"Pnn\" Nom | \"PP\" Nom | Nom | \"PrN\" | \"Adv\" Nom\n",
    "    Nom -> \"N\" | \"N\" \"Adj\" | \"At\" \"N\" | \"N\" \"V\" | \"PP\" \"PrN\" | \"PP\" \"PrN\" \"Adj\" | \"At\" \"N\" \"V\" \n",
    "    NP -> \"PrN\" | Nom | \"PrN\" \"Com\" NP \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. What is your set of POS tags?\n",
    "\n",
    "* show the list of strings (e.g., ['Adj', ...])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "POS_tags = ['N', 'Adj', 'PrN', 'At', 'V', 'Pnn', 'PP', 'Adv', 'Com']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Make a list for the POS tags that correspond to the sentence `s` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = ['timba', 'his', 'face', 'red', 'his', 'eye', 'black', 'in', 'winter']\n",
    "p = ['PrN', 'Pnn', 'N', 'Adj', 'Pnn', 'N', 'Adj', 'PP', 'N']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Parse the sentence (represented as POS tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP PrN)\n",
      "  (RP\n",
      "    (Ph Pnn (Nom N Adj))\n",
      "    (RP (Ph Pnn (Nom N Adj)) (RP (Ph PP (Nom N))))))\n"
     ]
    }
   ],
   "source": [
    "parser = nltk.RecursiveDescentParser(tamarian_grammar)\n",
    "for tree in parser.parse(p):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Credit! Do all of the above questions again, but add the sentence:\n",
    "\n",
    "'The beast of Tanagra Usani his army Jakka when the walls fell'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "*Done!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from client.api.notebook import Notebook\n",
    "ok = Notebook('a4.ok')\n",
    "ok.auth(inline=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.save_checkpoint();"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.save_notebook();"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving notebook... Saved 'A4-linguistics.ipynb'.\n",
      "Submit... 100% complete\n",
      "Assignment is due in 42 minutes and 16 seconds\n",
      "Submission successful for user: SajiaZafreen@u.boisestate.edu\n",
      "URL: https://okpy.org/bsu/nlp/sp21/a4/submissions/g2WGvZ\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ok.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
